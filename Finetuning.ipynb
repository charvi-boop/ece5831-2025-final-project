{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257,
     "referenced_widgets": [
      "5c0018d9ca874539869f29813eb8fd7d",
      "5b81c19fc4a74c81912f7cc2a2e03833",
      "f662a6c534c74113aa35e98a4d3a70bb",
      "8a55b340579f4635a601f910ca70602d",
      "74abf89017134fa9abee939935ed351a",
      "afa23aa6aa0c4a12b64ab91d7b90fda8",
      "f219891691324522a8324f9665c11148",
      "a7eeb4ef2d224a94a36f83054bdcd79e",
      "e89c4825acfb488eb461fc794eb076ed",
      "5f3afc724e38402886f1aa1533ddd1fc",
      "fd6f7691b5474ba69767a7d2d630df89",
      "16387ad73ace40899777f5f664a389f7",
      "4959d2e5d59d4daf9b59b2f110d91d4a",
      "a66dd07bf2034234adee1689adee4b9a",
      "cb04ac4dd5dc4239a6b8a306ae6a75a0",
      "70147a8533254683a12eb9485424528a",
      "c1cf4d649def405dbf8b1536e77760fe",
      "0115791b74d248958a1fde0722fe07fd",
      "f4386d992fa74590b74ca6f834b8b0a0",
      "e4f58c08fd2544cdb7498549f97304e0",
      "94533b5b653247a2a761e28227d60922",
      "0eb660fac45f470195d863ab75771995"
     ]
    },
    "id": "q_stBjdk8fqa",
    "outputId": "701f5bae-4f68-402a-f8e2-fc6dc4f4d4de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 rows.\n",
      "Training samples: 80000\n",
      "Validation samples: 20000\n",
      "\n",
      "Number of unique labels: 20\n",
      "Example label2id mapping: [('Bank account or service', 0), ('Checking or savings account', 1), ('Consumer Loan', 2), ('Credit card', 3), ('Credit card or prepaid card', 4)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0018d9ca874539869f29813eb8fd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16387ad73ace40899777f5f664a389f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example Data Point ---\n",
      "{'Product': 'Student loan', 'text': \"Nelnet contacted me concerning my student loan and their representative said I needed to consolidate the loan. I was concerned, due to financial losses I was counting on loan forgiveness. I was paying the loan on a regular basis and was under an income repayment plan. I was told the billing would resume in two months. This consolidation occurred for the months of XX/XX/XXXX and XXXX of XXXX. I was deeply concerned when Nelnet wanted to do this because I did not want any lapse in my repayment play. I did not ask for a consolidation. The loans had previously been consolidated early on. The representative reassured me that was not the case and my payment history would be continuous. Now after applying for loan forgiveness, I am informed I was placed on administrative forbearance by Nelnet for those two months so my record was interrupted. I specifically said that I did not want any lapse in my payment schedule. Now only one of the loans is showing as receiving continuous payments after this consolidation and on the one loan that is showing a recored, there are only 40 months of continuous payments recorded instead of over nine years. I was lied to by XXXX. I was afraid of their business dealings due to all of the recent bad publicity and now I understand why. I won't describe my situation but I have taught college level classes to disadvantaged and non-traditional students for over twenty years. However, I had two forbearances due to financial concerns but worked diligently to maintain a continuous payment record over the last nine years. This is incredibly distressing. I can't retire and am suffering from XXXX that may limit my future employment. I do not know what to do at this point.\", 'label': 18}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, ClassLabel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. Load our Sampled Data ---\n",
    "data_file = 'complaints_sample_100k.csv' # Make sure this is uploaded to Colab\n",
    "df = pd.read_csv(data_file)\n",
    "df = df.dropna(subset=['Consumer complaint narrative', 'Product'])\n",
    "\n",
    "print(f\"Loaded {len(df)} rows.\")\n",
    "\n",
    "# --- 2. Create Training and Validation Sets ---\n",
    "# We'll split the data again. The 'test' set here is what the model\n",
    "# will use during training to check its own performance (a validation set).\n",
    "df_train, df_val = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2, # 20% for validation\n",
    "    random_state=42,\n",
    "    stratify=df['Product']\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(df_train)}\")\n",
    "print(f\"Validation samples: {len(df_val)}\")\n",
    "\n",
    "# --- 3. Convert to Hugging Face Dataset object ---\n",
    "# This is the format the 'transformers' library expects\n",
    "train_dataset = Dataset.from_pandas(df_train.reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(df_val.reset_index(drop=True))\n",
    "\n",
    "# --- 4. CRITICAL: Create Label Mappings ---\n",
    "# LLMs don't understand text labels like \"Mortgage\". They need numbers (0, 1, 2...).\n",
    "# We must create a mapping from strings to integers (id2label, label2id)\n",
    "\n",
    "# Get a sorted list of unique product names\n",
    "class_names = sorted(df['Product'].unique())\n",
    "\n",
    "# Create the ClassLabel feature\n",
    "cl = ClassLabel(names=class_names)\n",
    "\n",
    "# Create the two mapping dictionaries we will need later\n",
    "label2id = {name: i for i, name in enumerate(class_names)}\n",
    "id2label = {i: name for i, name in enumerate(class_names)}\n",
    "\n",
    "num_labels = len(class_names)\n",
    "\n",
    "print(f\"\\nNumber of unique labels: {num_labels}\")\n",
    "print(f\"Example label2id mapping: {list(label2id.items())[:5]}\")\n",
    "\n",
    "# --- 5. Create a function to convert text labels to integer IDs ---\n",
    "def map_labels(example):\n",
    "    example['label'] = label2id[example['Product']]\n",
    "    return example\n",
    "\n",
    "# Apply this function to both datasets\n",
    "train_dataset = train_dataset.map(map_labels, batched=False)\n",
    "val_dataset = val_dataset.map(map_labels, batched=False)\n",
    "\n",
    "# We can also rename the text column to what the model expects\n",
    "train_dataset = train_dataset.rename_column(\"Consumer complaint narrative\", \"text\")\n",
    "val_dataset = val_dataset.rename_column(\"Consumer complaint narrative\", \"text\")\n",
    "\n",
    "print(\"\\n--- Example Data Point ---\")\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570,
     "referenced_widgets": [
      "758ff35e6b6a41c08d7dd775f72a0040",
      "24874f23b8464a199c77213289af8f4b",
      "4affc0dc78234a97a50bcd2ec6643104",
      "06fea68c0dc94b4097eac7de23062f07",
      "c222a677d7b5411ab8b39cba0187b6f5",
      "997471881c58422ebd68944fe713f86f",
      "6f1cb8bf897a45358bf5fc030452f157",
      "0509a948da9843bd91e3014da015787c",
      "83b286555d164207890467f5bdef4de1",
      "867eab8d647744b0920b7629204cef93",
      "9213958cbc91402bbd9c52a9d214b2cb"
     ]
    },
    "id": "rH5sUI0y8foT",
    "outputId": "58b0afb1-45bb-4b08-cb6a-0f14523b668f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758ff35e6b6a41c08d7dd775f72a0040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3.1-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded in 4-bit.\n",
      "LlamaForSequenceClassification(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096, padding_idx=128001)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (score): Linear(in_features=4096, out_features=20, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig\n",
    "\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",       # Use \"nf4\" (NormalFloat 4) for high precision\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # Compute in bfloat16 for speed\n",
    "    bnb_4bit_use_double_quant=True, # Use double quantization for better accuracy\n",
    ")\n",
    "\n",
    "# --- 2. Load the Tokenizer ---\n",
    "# The tokenizer converts text to numbers (tokens)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=HF_TOKEN)\n",
    "\n",
    "# Llama models don't have a default padding token.\n",
    "# We'll set it to the End-of-Sequence (EOS) token.\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model_config = {\"pad_token_id\": tokenizer.eos_token_id}\n",
    "\n",
    "print(\"Tokenizer loaded.\")\n",
    "\n",
    "# --- 3. Load the 4-bit Model ---\n",
    "# We specify 'AutoModelForSequenceClassification'. This adds a classification head (a simple linear layer)on top of the Llama 3 model, ready for fine-tuning.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config, # Apply our 4-bit config\n",
    "    device_map=\"auto\",              # Automatically use the GPU\n",
    "    num_labels=num_labels,          \n",
    "    id2label=id2label,              \n",
    "    label2id=label2id,\n",
    "    **model_config                  \n",
    ")\n",
    "\n",
    "print(\"Model loaded in 4-bit.\")\n",
    "print(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "7d86c3655fe044c184c0bc0ac1a3fa79",
      "bc0e9ad2fc2a43fba008d5b754241c41",
      "5f5d916b4eee4cc1848e00ffeb53962d",
      "ec6d54c791c643268ff7d6bedcf5007c",
      "e39f5344c3af4127b1c7b1a55cda32bd",
      "bd0a18e9ce41477caf4b4623649d084b",
      "bf98586161d54277a2e5b80b7ad04a99",
      "550ca49d547844d597e119b900ae8d39",
      "dfb50d397b964deabbf0e5e4b8cc06be",
      "2a8ea29753ad423fb6da02d5f0f335b3",
      "b1c9354ebb54436d991f2dd42fc8749e",
      "95bd3f66f6a143dcba86e3ddc6040fee",
      "e8ee6977d1894d0e9ae602c4198fe8fc",
      "32d3ec43b172474294fa163370fd350c",
      "6ad072f20f424f7f827d5d820dd281c3",
      "1348beeb5fba4bc2b702873a094054f7",
      "ea852fe2ce284769986bbce2ba212a93",
      "29c04157eacf40419014a6e047d56af5",
      "7dee7a6c735047d294583b2830ee8eac",
      "0cac41e6f75d4daba1e2b156e12cbef0",
      "4efe4ec2b2a4419886e850bddcca7531",
      "7237bbf3dceb4cf0a87b738764774262"
     ]
    },
    "id": "yZbDFwTw8fmG",
    "outputId": "8599dd6e-be24-4284-8603-6f5b44fba31d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing training dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d86c3655fe044c184c0bc0ac1a3fa79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing validation dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bd3f66f6a143dcba86e3ddc6040fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example Tokenized Data Point ---\n",
      "{'label': tensor(18), 'input_ids': tensor([128000,     45,    301,   4816,  25559,    757,  18815,    856,   5575,\n",
      "         11941,    323,    872,  18740,   1071,    358,   4460,    311,  74421,\n",
      "           279,  11941,     13,    358,    574,  11920,     11,   4245,    311,\n",
      "          6020,  18151,    358,    574,  26060,    389,  11941,  53150,     13,\n",
      "           358,    574,  12798,    279,  11941,    389,    264,   5912,   8197,\n",
      "           323,    574,   1234,    459,   8070,  71118,   3197,     13,    358,\n",
      "           574,   3309,    279,  34631,   1053,  16063,    304,   1403,   4038,\n",
      "            13,   1115,  60732,  10222,    369,    279,   4038,    315,  30388,\n",
      "            14,   6277,     14,  24769,    323,  20572,     55,    315,  20572,\n",
      "            55,     13,    358,    574,  17693,  11920,    994,  89461,   4816,\n",
      "          4934,    311,    656,    420,   1606,    358,   1550,    539,   1390,\n",
      "           904,  90417,    304,    856,  71118,   1514,     13,    358,   1550,\n",
      "           539,   2610,    369,    264,  60732,     13,    578,  17017,   1047,\n",
      "          8767,   1027,  60391,   4216,    389,     13,    578,  18740,  32834,\n",
      "          3149,    757,    430,    574,    539,    279,   1162,    323,    856,\n",
      "          8323,   3925,   1053,    387,  19815,     13,   4800,   1306,  19486,\n",
      "           369,  11941,  53150,     11,    358,   1097,  16369,    358,    574,\n",
      "          9277,    389,  23541,  55844,    686,    685,    555,  89461,   4816,\n",
      "           369,   1884,   1403,   4038,    779,    856,   3335,    574,  37883,\n",
      "            13,    358,  11951,   1071,    430,    358,   1550,    539,   1390,\n",
      "           904,  90417,    304,    856,   8323,   9899,     13,   4800,   1193,\n",
      "           832,    315,    279,  17017,    374,   9204,    439,  12588,  19815,\n",
      "         14507,   1306,    420,  60732,    323,    389,    279,    832,  11941,\n",
      "           430,    374,   9204,    264,   1421,   3093,     11,   1070,    527,\n",
      "          1193,    220,   1272,   4038,    315,  19815,  14507,  12715,   4619,\n",
      "           315,    927,  11888,   1667,     13,    358,    574,  47253,    311,\n",
      "           555,  20572,     55,     13,    358,    574,  16984,    315,    872,\n",
      "          2626,  67029,   4245,    311,    682,    315,    279,   3293,   3958,\n",
      "         43763,    323,   1457,    358,   3619,   3249,     13,    358,   2834,\n",
      "           956,   7664,    856,   6671,    719,    358,    617,  15972,   7926,\n",
      "          2237,   6989,    311,  80947,    323,   2536,  10398,    329,   3079,\n",
      "          4236,    369,    927,  17510,   1667,     13,   4452,     11,    358,\n",
      "          1047,   1403,  55844,    686,   3095,   4245,    311,   6020,  10742,\n",
      "           719,   6575,  91705,    311,  10519,    264,  19815,   8323,   3335,\n",
      "           927,    279,   1566,  11888,   1667,     13,   1115,    374,  17235,\n",
      "         35104,    287,     13,    358,    649,    956,  16177,    323,   1097,\n",
      "         16066,    505,  20572,     55,    430,   1253,   4017,    856,   3938,\n",
      "         14740,     13,    358,    656,    539,   1440,   1148,    311,    656,\n",
      "           520,    420,   1486,     13, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,\n",
      "        128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Create Tokenization Function ---\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize the 'text' field.\n",
    "    # padding=\"max_length\" ensures all sequences are the same size.\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True, # ensures no sequence is longer than the model can handle\n",
    "        max_length=512 \n",
    "    )\n",
    "\n",
    "# --- 2. Apply Tokenization to Datasets ---\n",
    "# We use .map() to apply the function to every example in our datasets.\n",
    "# batched=True processes multiple examples at once for speed.\n",
    "print(\"\\nTokenizing training dataset...\")\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"Tokenizing validation dataset...\")\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# --- 3. Clean Up Columns ---\n",
    "# The model only needs 'input_ids', 'attention_mask', and 'label'.\n",
    "# We can remove the old text columns to save space.\n",
    "tokenized_train_dataset = tokenized_train_dataset.remove_columns([\"Product\", \"text\"])\n",
    "tokenized_val_dataset = tokenized_val_dataset.remove_columns([\"Product\", \"text\"])\n",
    "\n",
    "# Tell the dataset to return PyTorch tensors\n",
    "tokenized_train_dataset.set_format(\"torch\")\n",
    "tokenized_val_dataset.set_format(\"torch\")\n",
    "\n",
    "print(\"\\n--- Example Tokenized Data Point ---\")\n",
    "print(tokenized_train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "O8A7USBR8fj1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# This function will be called by the Trainer at each evaluation step\n",
    "def compute_metrics(eval_pred):\n",
    "    # eval_pred is a tuple containing (logits, labels)\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # We get the model's predictions by finding the class with the highest logit\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Calculate basic accuracy\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # Calculate the weighted F1-score, just like our baseline\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "\n",
    "    # Return a dictionary of the metrics\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nbCrvPDh8fhX",
    "outputId": "6efd76e6-713b-4cde-8ff1-6f9c3a0972da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,897,664 || all params: 7,511,904,256 || trainable%: 0.0918\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "\n",
    "# --- 1. Prepare model for 4-bit training ---\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# --- 2. Define LoRA Config ---\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS, # Sequence Classification task\n",
    "    r=16,                       # Rank of the adapter\n",
    "    lora_alpha=32,              # Scaling factor\n",
    "    lora_dropout=0.05,          # Dropout\n",
    "    target_modules=[\"q_proj\", \"v_proj\"] # Attach LoRA to attention layers\n",
    ")\n",
    "\n",
    "# --- 3. Wrap the model with LoRA ---\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "AeHAywku8fcy",
    "outputId": "0f348f98-24ee-44a4-a0a5-408c96c2d9dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1519846038.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 3:44:57, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>7.667200</td>\n",
       "      <td>1.844932</td>\n",
       "      <td>0.460150</td>\n",
       "      <td>0.408718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>6.331600</td>\n",
       "      <td>1.473828</td>\n",
       "      <td>0.518750</td>\n",
       "      <td>0.479638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=9.033110885620117, metrics={'train_runtime': 13513.4535, 'train_samples_per_second': 0.118, 'train_steps_per_second': 0.007, 'total_flos': 3.4340377460736e+16, 'train_loss': 9.033110885620117, 'epoch': 0.02})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "# --- 1. Define Training Arguments ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama3-classification-v1\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    max_steps=100,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    fp16=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# --- 2. Data Collator ---\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# --- 3. Initialize Trainer ---\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# --- 4. START TRAINING ---\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "id": "-I1w5LXkArpJ",
    "outputId": "7d1f7c10-657a-4396-9105-e44b58b05e04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3656500438.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimized training run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 6:08:36, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>12.822000</td>\n",
       "      <td>1.332682</td>\n",
       "      <td>0.542000</td>\n",
       "      <td>0.446772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>8.637500</td>\n",
       "      <td>1.003595</td>\n",
       "      <td>0.648000</td>\n",
       "      <td>0.638427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>7.553700</td>\n",
       "      <td>1.087633</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>0.592390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>6.941600</td>\n",
       "      <td>0.866296</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.695252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.310300</td>\n",
       "      <td>0.883998</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.654253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>7.414700</td>\n",
       "      <td>0.804509</td>\n",
       "      <td>0.726000</td>\n",
       "      <td>0.710095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.969900</td>\n",
       "      <td>0.867924</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>0.631216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>6.773200</td>\n",
       "      <td>0.731438</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.734822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>5.781500</td>\n",
       "      <td>0.730173</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.727012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>6.085600</td>\n",
       "      <td>0.750126</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.724813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>6.344200</td>\n",
       "      <td>0.663550</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.760481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>5.882600</td>\n",
       "      <td>0.669834</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>0.747605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "# --- OPTIMIZATION: Use a tiny validation set for speed ---\n",
    "small_val_dataset = tokenized_val_dataset.select(range(500))\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# --- REVISED ARGUMENTS: 4-Hour Run ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama3-classification-final\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    max_steps=1200,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,         # Check progress every 100 steps\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,         # Save progress every 100 steps\n",
    "    fp16=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=small_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Starting optimized training run\")\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model\n",
    "trainer.save_model(\"./llama3-classification-final\")\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "id": "jWxUeH2t6cYq",
    "outputId": "ce52ed73-dba0-4e8f-b866-bc3e698c4abd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1199820915.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fast Evaluation (Batch Size 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL OFFICIAL F1 SCORE: 0.7333 ===\n",
      "\n",
      "Classification Report:\n",
      "                                                                              precision    recall  f1-score   support\n",
      "\n",
      "                                                     Bank account or service       0.67      0.17      0.27        12\n",
      "                                                 Checking or savings account       0.79      0.83      0.81       139\n",
      "                                                               Consumer Loan       0.00      0.00      0.00         5\n",
      "                                                                 Credit card       0.31      0.24      0.27        79\n",
      "                                                 Credit card or prepaid card       0.48      0.56      0.52        91\n",
      "                                                            Credit reporting       0.00      0.00      0.00        31\n",
      "                         Credit reporting or other personal consumer reports       0.82      0.80      0.81      1268\n",
      "Credit reporting, credit repair services, or other personal consumer reports       0.64      0.73      0.69       706\n",
      "                                                             Debt collection       0.75      0.72      0.73       335\n",
      "                                                   Debt or credit management       0.00      0.00      0.00         2\n",
      "                          Money transfer, virtual currency, or money service       0.90      0.89      0.89       100\n",
      "                                                             Money transfers       0.00      0.00      0.00         1\n",
      "                                                                    Mortgage       0.89      0.90      0.90       110\n",
      "                                                     Other financial service       0.00      0.00      0.00         0\n",
      "                                                                 Payday loan       0.00      0.00      0.00         3\n",
      "                                   Payday loan, title loan, or personal loan       0.38      0.42      0.40        19\n",
      "                     Payday loan, title loan, personal loan, or advance loan       0.50      0.11      0.18         9\n",
      "                                                                Prepaid card       0.00      0.00      0.00         5\n",
      "                                                                Student loan       0.76      0.84      0.80        50\n",
      "                                                       Vehicle loan or lease       0.62      0.43      0.51        35\n",
      "\n",
      "                                                                    accuracy                           0.74      3000\n",
      "                                                                   macro avg       0.43      0.38      0.39      3000\n",
      "                                                                weighted avg       0.73      0.74      0.73      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# 1. Define NEW arguments just for fast evaluation\n",
    "# We use batch size 16 to speed up evaluation\n",
    "eval_args = TrainingArguments(\n",
    "    output_dir=\"./eval_temp\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    report_to=\"none\",\n",
    "    fp16=True \n",
    ")\n",
    "\n",
    "# 2. Create a NEW Trainer instance\n",
    "eval_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=eval_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Starting Fast Evaluation (Batch Size 16)\")\n",
    "\n",
    "# 3. Predict\n",
    "fast_val_dataset = tokenized_val_dataset.shuffle(seed=42).select(range(3000))\n",
    "\n",
    "# 2. Run Prediction on Validation Set\n",
    "predictions_output = eval_trainer.predict(fast_val_dataset)\n",
    "\n",
    "# 4. Process Results\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "y_preds = np.argmax(predictions_output.predictions, axis=-1)\n",
    "y_true = predictions_output.label_ids\n",
    "\n",
    "final_f1 = f1_score(y_true, y_preds, average='weighted')\n",
    "print(f\"\\n=== FINAL OFFICIAL F1 SCORE: {final_f1:.4f} ===\")\n",
    "\n",
    "all_label_ids = sorted(id2label.keys())\n",
    "all_label_names = [id2label[i] for i in all_label_ids]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_preds, target_names=all_label_names, labels=all_label_ids))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}